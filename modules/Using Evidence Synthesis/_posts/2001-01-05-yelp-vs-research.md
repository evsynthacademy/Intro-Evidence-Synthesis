---
  title: "Evaluating Yelp reviews vs evaluating research studies"
---

# Evaluating Yelp reviews vs research studies


The methods you use to evaluate Yelp reviews are similar to the methods scientists use to screen research studies. Here are just a few examples:


## Yelp Review or Research Study

| Yelp Review | Research Study |
| ----------- | ------------- | 
| How many reviews has this yelper written? | How many studies has this researcher conducted? | 
| Does this review have typos? Does this study have mathematical errors? | 
| Is this review talking about something irrelevant, like available parking? | Is this study about my specific research question? AKA does it include outcomes of importance? | 
| Does it seem like this yelper was paid for a good review? | Who sponsored this research? AKA are there conflicts of interest? | 
| When was this review conducted? Has anything changed since then? | Has any key research come forward since the study? | 

Some of these questions are easy to answer.  You can notice typos and see a Yelper’s review history right away. Other questions are harder to answer. How do you know if something has changed since most of the positive reviews were posted? How can you tell if a reviewer is related to the owner of the donut shop?  

That’s why researchers often take one last step to evaluate the existing evidence: they submit a draft report for peer review so outside experts in the field can comment and let them know if they missed or misinterpreted anything. You might do this by asking your friends about their real experiences buying donuts in Providence.

